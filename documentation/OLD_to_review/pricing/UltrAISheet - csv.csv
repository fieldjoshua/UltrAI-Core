# Core Template Variables
"Variable,Description,Example Usage"
"{prompt},""The original user query or input text"",""What strategies should a startup use to gain market share?"""
"{responses},""Collection of responses from previous stage models"",""[Response from LLaMA, Response from ChatGPT, Response from Gemini]"""
"{initial_responses},""Collection of first-stage model outputs"",""[Initial ChatGPT analysis, Initial Gemini analysis, Initial LLaMA analysis]"""
"{meta_responses},""Collection of second-stage analyses"",""[Meta-analysis from ChatGPT, Meta-analysis from Gemini]"""
"{response.content},""Content of a specific model response for evaluation"",""The key strategies for market penetration include..."""
"{model_name},""Name of the specific model being used or evaluated"",""ChatGPT or Gemini"""
"{stage},""Current processing stage identifier"",""initial, meta, synthesis"""

# Analysis Stages and Templates
"Stage,Template,Purpose,Models Used,Output Format"
"Initial Analysis,""Please analyze the following: {prompt}"",""First-level independent analysis of user prompt"",""ChatGPT, Gemini, LLaMA"",""Plain text or structured based on prompt"""
"Meta Analysis,""Analyze these model responses and identify: 1. Key technical insights 2. Strategic implications 3. Areas of agreement/disagreement 4. Unique perspectives from each model Responses to analyze: {responses}"",""Cross-analysis of initial responses to identify patterns and insights"",""ChatGPT, Gemini"",""Structured analysis with categories"""
"Ultra Synthesis,""Create a comprehensive synthesis including: 1. Technical implementation details 2. Strategic insights 3. Consensus points across models 4. Key recommendations Initial analyses: {initial_responses} Meta analyses: {meta_responses}"",""Comprehensive integration of all previous analyses"",""Configurable via ultra_engine parameter (default ChatGPT)"",""Comprehensive structured synthesis"""
"Hyper-Level Analysis,""Perform a hyper-level analysis of all previous responses: {responses}"",""Final refinement integrating insights from all stages"",""ChatGPT"",""Most polished final output"""
"Quality Evaluation,""Evaluate this response on a scale of 0-1 for: 1. Coherence: Clear and logical flow 2. Technical Depth: Detailed technical insights 3. Strategic Value: Actionable strategic insights 4. Uniqueness: Novel perspectives Response to evaluate: {response.content} Return scores in JSON format."",""Internal quality assessment for metrics tracking"",""ChatGPT"",""JSON with numeric scores"""

# Configuration Parameters and Settings
"Parameter,Description,Default Value,Impact on Prompts"
"output_format,""Format for final output"",""plain (alternatives: markdown, json)"",""Affects how responses are formatted"""
"ultra_engine,""Model to use for ultra synthesis stage"",""chatgpt (alternatives: llama, gemini)"",""Determines which model performs the critical synthesis"""
"rate_limits,""API call frequency limits"",""ChatGPT: 3/min, LLaMA: 5/min, Gemini: 10/min"",""Controls API call pacing"""
"cache_enabled,""Whether to cache model responses"",""True"",""Affects whether identical prompts use cached results"""
"max_retries,""Maximum API retry attempts"",""3"",""Controls persistence on API failures"""

# Performance Metrics Tracked
"Metric,Description,Format,Usage"
"response_times,""Time taken for each model to respond"",""Array of floats"",""Performance optimization"""
"success_rates,""Percentage of successful API calls per model"",""Dictionary {model: {success: int, total: int}}"",""System reliability monitoring"""
"token_usage,""Count of tokens consumed per model"",""Dictionary {model: int}"",""Cost tracking and optimization"""
"quality_scores,""Quality evaluation metrics per model"",""Dictionary {model: [scores]}"",""Model performance assessment"""

# System Processing Addons
"Addon,Description,When Applied,Effect"
"Hardware Acceleration,""Detection and use of specialized hardware"",""System initialization"",""Improved performance on compatible systems (especially Apple Silicon)"""
"Exponential Backoff,""Progressive wait time between retry attempts"",""During API failures"",""More robust error handling"""
"Token Usage Tracking,""Counting tokens used in requests/responses"",""Every API call"",""Cost monitoring and optimization"""
"Asynchronous Processing,""Parallel execution of model calls"",""All multi-model stages"",""Reduced total processing time"""
"Response Caching,""Storage of previous responses"",""When cache_enabled=True"",""Faster responses and reduced API costs"""