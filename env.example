# Ultra Environment Configuration
# Copy this file to .env to set your environment variables

# ------------------------------
# Core Configuration
# ------------------------------
PORT=8000
NODE_ENV=development
LOG_LEVEL=info
DEBUG=false

# ------------------------------
# Security
# ------------------------------
# Generate a secure random string for signing JWT tokens
JWT_SECRET=your-jwt-secret-here
# CORS settings
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173

# ------------------------------
# LLM API Keys
# ------------------------------
# OpenAI API keys (Required for GPT models)
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_ORG_ID=org-xxxxxxxxxxxxxxxxxxxx

# Anthropic API key (Required for Claude models)
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Google API key (Required for Gemini models)
GOOGLE_API_KEY=AIza-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Ollama settings (for local models)
OLLAMA_BASE_URL=http://localhost:11434
ENABLE_OLLAMA=false

# ------------------------------
# Database Configuration
# ------------------------------
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=ultra

# ------------------------------
# Caching Configuration
# ------------------------------
ENABLE_CACHE=true
CACHE_TTL=3600
MAX_CACHE_ITEMS=1000

# ------------------------------
# Performance Settings
# ------------------------------
# Maximum concurrent requests for each LLM provider
MAX_CONCURRENT_OPENAI=10
MAX_CONCURRENT_ANTHROPIC=5
MAX_CONCURRENT_GOOGLE=8
MAX_CONCURRENT_OLLAMA=2

# Maximum request timeout in milliseconds
REQUEST_TIMEOUT=60000

# ------------------------------
# Feature Flags
# ------------------------------
ENABLE_MOCK_LLM=true
ENABLE_DOCUMENT_PROCESSING=true
ENABLE_PRICING=false
ENABLE_AUTH=false

# ------------------------------
# Monitoring and Analytics
# ------------------------------
ENABLE_TELEMETRY=false
SENTRY_DSN=
ENABLE_PERFORMANCE_METRICS=true
